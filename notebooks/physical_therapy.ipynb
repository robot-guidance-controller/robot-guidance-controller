{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preamble\n",
    "from virtual_dynamics import SimpleVirtualDynamics\n",
    "from robot import Robot\n",
    "from app_loop import AppLoop\n",
    "from vocalizer import Vocalizer\n",
    "from plot_client import PlotClient\n",
    "from phrase_mapping import PHRASE_MAPPING, WORDS_PER_PHRASE\n",
    "from rgbd_stream import RGBDStream_iOS\n",
    "from camera_feed import CameraFeed\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "from model import DualAutoencoderModel\n",
    "from globals import FORCE_SAMPLE_COUNT, FORCE_CURVE_DURATION\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobotApp(AppLoop):\n",
    "    MASS = 10.0\n",
    "    DAMPENING = 30.0\n",
    "    AXES = Robot.TRANSLATION\n",
    "\n",
    "    def __init__(self, use_plotter: bool = False, use_camera: bool = False, record_data: bool = False):\n",
    "        super().__init__()\n",
    "        self.use_plotter = use_plotter\n",
    "        self.use_camera = use_camera\n",
    "        self.record_data = record_data\n",
    "\n",
    "    def startup(self) -> None:\n",
    "        self.robot = Robot(\"169.254.9.43\",\n",
    "                           translational_force_deadband=5.0,\n",
    "                           rotational_force_deadband=0.5)\n",
    "        self.robot.control.zeroFtSensor()\n",
    "        self.p0 = self.robot.INIT_POSE[:3]\n",
    "        self.F_ext = np.zeros_like(self.p0)\n",
    "        self.F_r = np.zeros_like(self.F_ext)\n",
    "        self.F_v = np.zeros_like(self.F_ext)\n",
    "\n",
    "        self.dynamics = SimpleVirtualDynamics(self.MASS, B=self.DAMPENING, K=0.0)\n",
    "\n",
    "        self.path, self.v_path, self.a_path = self.load_reference_path('../data/reference_path.csv')\n",
    "        self.forward_state = True\n",
    "\n",
    "        self.P = 0.5\n",
    "        self.V = 0.5\n",
    "        self.k = 120.0 * 10.0 * 0.5 * 0.8\n",
    "        self.b = 40.0 * 10.0 * 0.8\n",
    "\n",
    "        self.speaking_start_t = -1000.0\n",
    "        self.speaking_start_V = 0.5\n",
    "\n",
    "        self.vocalizer = Vocalizer()\n",
    "        with open('../models/svm_knn.pkl', 'rb') as file:\n",
    "            self.model = pickle.load(file)\n",
    "\n",
    "        if self.use_plotter:\n",
    "            self.plotter = PlotClient()\n",
    "            self.plotter.create_plot(\"A\", title=\"Estimated Compliance\", xlabel=\"Time (s)\", ylabel=\"Compliance Level\")\n",
    "            self.plotter.create_line(\"A\", \"x\", plot_style='-', color='#DF2935', label='P')\n",
    "            self.plotter.create_line(\"A\", \"y\", plot_style='-', color='#4DA167', label='V')\n",
    "\n",
    "        if self.use_camera:\n",
    "            rgbd_stream = RGBDStream_iOS()\n",
    "            calibration_matrix = np.load('calibration_matrix.npy')\n",
    "            self.camera_feed = CameraFeed('Camera Feed', rgbd_stream, calibration_matrix)\n",
    "\n",
    "        if self.record_data:\n",
    "            self.data = []\n",
    "            time.sleep(7)\n",
    "\n",
    "    def load_reference_path(self, file_path: str) -> NDArray:\n",
    "        data = pd.read_csv(file_path)\n",
    "\n",
    "        path = np.stack([data['p_x'].values, data['p_y'].values, data['p_z'].values], axis=1)\n",
    "        path += self.p0 - path[0]\n",
    "\n",
    "        v_path = np.stack([data['v_x'].values, data['v_y'].values, data['v_z'].values], axis=1)\n",
    "        a_path = np.stack([data['a_x'].values, data['a_y'].values, data['a_z'].values], axis=1)\n",
    "\n",
    "        return path, v_path, a_path\n",
    "\n",
    "    def update_path(self) -> None:\n",
    "        p = self.robot.get_pose(self.AXES)\n",
    "\n",
    "        if p[0] <= self.path[-1, 0] if self.forward_state else p[0] >= self.path[0, 0]:\n",
    "            self.forward_state = not self.forward_state\n",
    "            self.v_path *= -1.0\n",
    "\n",
    "    def get_target(self, p: NDArray) -> NDArray:\n",
    "        distances = np.linalg.norm(self.path - p, axis=1)\n",
    "        index = np.argmin(distances)\n",
    "        return self.path[index], self.v_path[index]\n",
    "\n",
    "    def update_F_ext(self, dt: float) -> None:\n",
    "        alpha = 1.0 - np.exp(-dt * 32.0 * 0.25)\n",
    "        F_ext = self.robot.get_force(self.AXES)\n",
    "        self.F_ext = alpha * F_ext + (1.0 - alpha) * self.F_ext\n",
    "\n",
    "    def compute_costs(self) -> Tuple[float, float]:\n",
    "        return (self.P + self.V) * 0.5, 1.0 - self.V\n",
    "\n",
    "    def compute_F_ref_curve(self, duration: float = FORCE_CURVE_DURATION, n_samples: int = FORCE_SAMPLE_COUNT) -> NDArray:\n",
    "        F_ref_curve = []\n",
    "\n",
    "        p = self.robot.get_pose(self.AXES)\n",
    "        v = self.robot.get_velocity(self.AXES)\n",
    "        p_ref, v_ref = self.get_target(p)\n",
    "        dt = duration / n_samples\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            p_ref, v_ref = self.get_target(p)\n",
    "            F_ref = -self.k * (p - p_ref) - self.b * (v - v_ref)\n",
    "            v += (F_ref - self.DAMPENING * v) / self.MASS * dt\n",
    "            p += v * dt\n",
    "            F_ref_curve.append(F_ref)\n",
    "\n",
    "        return np.linspace(0.0, duration, n_samples), np.array(F_ref_curve)\n",
    "    \n",
    "    def split_F_ref(self, F_ref: float | NDArray, c_p: float, c_v: float) -> Tuple[float | NDArray, float | NDArray]:\n",
    "        return c_v / (c_p + c_v) * F_ref, c_p / (c_p + c_v) * F_ref\n",
    "    \n",
    "    def generate_phrase(self, F_v_curve: NDArray) -> str:\n",
    "        impulse_curve = F_v_curve.cumsum(axis=0) * FORCE_CURVE_DURATION / FORCE_SAMPLE_COUNT\n",
    "        phrase = self.model.force_to_phrase(impulse_curve[None, :])[0]\n",
    "        phrase_text = ' '.join(phrase).strip()\n",
    "        return PHRASE_MAPPING[phrase_text]\n",
    "\n",
    "    def speaking_period(self) -> float:\n",
    "        return WORDS_PER_PHRASE / (0.36 * 2.2 ** (2 - self.P - self.V))\n",
    "    \n",
    "    def log_normal(self, x: float, mu: float, sigma: float) -> float:\n",
    "        return np.exp(-(np.log(x) - mu) ** 2 / (2.0 * sigma ** 2)) / (x * sigma * np.sqrt(2.0 * np.pi))\n",
    "\n",
    "    def normal(self, x: float, mu: float, sigma: float) -> float:\n",
    "        return np.exp(-0.5 * ((x - mu) / sigma) ** 2) / np.sqrt(2.0 * np.pi * sigma ** 2)\n",
    "\n",
    "    def estimate_state(self, F_r: NDArray, F_v: NDArray, t: float, dt: float) -> None:\n",
    "        alpha = 1.0 - np.exp(-0.025 * dt)\n",
    "        uncertainty = np.sqrt(dt / 0.004)\n",
    "\n",
    "        z_p = np.sum(F_r * self.F_ext) / np.linalg.norm(F_r)\n",
    "        P_pred = alpha * (1.0 - self.P) + (1.0 - alpha) * self.P\n",
    "        self.P = self.normal(z_p, mu=0.0, sigma=200.0 / uncertainty) * P_pred\n",
    "        self.P = self.P / (self.P + self.normal(z_p, mu=-15.0, sigma=200.0 / uncertainty) * (1.0 - P_pred))\n",
    "\n",
    "        # P_pred = Pr(P=1|P=0) * (1 - P_hat) + Pr(P=1|P=1) * P_hat\n",
    "        # P_hat = Pr(z_p|P=1) * P_pred / (Pr(z_p|P=0) * (1 - P_pred) + Pr(z_p|P=1) * P_pred)\n",
    "\n",
    "        decay = np.exp(-4.0 * (np.log(max(t - self.speaking_start_t, 1e-6)) - np.log(2.5)) ** 2)\n",
    "        if decay > 0.01:\n",
    "            z_v = np.sum(F_v * self.F_ext) / np.linalg.norm(F_v) * decay\n",
    "            V_pred = alpha * (1.0 - self.V) + (1.0 - alpha) * self.V\n",
    "            self.V = self.normal(z_v, mu=0.0, sigma=200.0 / uncertainty) * V_pred\n",
    "            self.V = self.V / (self.V + self.normal(z_v, mu=-10.0, sigma=200.0 / uncertainty) * (1.0 - V_pred))\n",
    "\n",
    "    def update(self, t: float, dt: float) -> None:\n",
    "        period_start = self.robot.control.initPeriod()\n",
    "        self.update_path()\n",
    "        self.update_F_ext(dt)\n",
    "\n",
    "        c_p, c_v = self.compute_costs()\n",
    "        t_curve, F_ref_curve = self.compute_F_ref_curve()\n",
    "        F_r_curve, F_v_curve = self.split_F_ref(F_ref_curve, c_p, c_v)\n",
    "        F_r, F_v = F_r_curve[0], F_v_curve[0]\n",
    "\n",
    "        phrase = self.generate_phrase(F_v_curve)\n",
    "        if t - self.speaking_start_t > 4.0 and t - self.speaking_start_t < 4.5 and self.V - self.speaking_start_V > 0.05:\n",
    "            spoke_encouraging = self.vocalizer.utter(\"good job\")\n",
    "        else:\n",
    "            spoke_encouraging = False\n",
    "\n",
    "        if t - self.speaking_start_t > self.speaking_period() and self.vocalizer.utter(phrase):\n",
    "            self.speaking_start_t = t\n",
    "            self.speaking_start_V = self.V\n",
    "            spoke_instructional = True\n",
    "        else:\n",
    "            spoke_instructional = False\n",
    "\n",
    "        self.estimate_state(F_r, F_v, t, dt)\n",
    "\n",
    "        self.F_r = 0.25 * F_r + 0.75 * self.F_r\n",
    "        self.F_v = 0.25 * F_v + 0.75 * self.F_v\n",
    "        self.dynamics.apply_force(self.F_ext + self.F_r, dt)\n",
    "        self.robot.set_velocity(self.dynamics.get_velocity(),\n",
    "                                Robot.TRANSLATION, acceleration=10)\n",
    "\n",
    "        self.robot.control.waitPeriod(period_start)\n",
    "\n",
    "        if self.use_plotter:\n",
    "            self.plotter.update_line(\"A\", \"x\", (t, self.P))\n",
    "            self.plotter.update_line(\"A\", \"y\", (t, self.V))\n",
    "            self.plotter.config_plot(\"A\", xlim=(t - 30, t), ylim=(0, 1))\n",
    "\n",
    "        if self.use_camera:\n",
    "            p = self.robot.get_pose(self.AXES)\n",
    "            p_r = p + self.F_r / (np.linalg.norm(self.F_r) + 1e-6) * 0.075 * np.log(np.linalg.norm(self.F_r) + 1.0)\n",
    "            p_v = p + self.F_v / (np.linalg.norm(self.F_v) + 1e-6) * 0.075 * np.log(np.linalg.norm(self.F_v) + 1.0)\n",
    "            p_h = p + self.F_ext / (np.linalg.norm(self.F_ext) + 1e-6) * 0.075 * np.log(np.linalg.norm(self.F_ext) + 1.0)\n",
    "            self.camera_feed.draw_world_arrow(p - np.array([0.0, 0.0, 0.025]), p_r - np.array([0.0, 0.0, 0.025]), thickness=6, color=(0x3C / 0xFF, 0x91 / 0xFF, 0xE6 / 0xFF))\n",
    "            self.camera_feed.draw_world_arrow(p + np.array([0.0, 0.0, 0.025]), p_v + np.array([0.0, 0.0, 0.025]), thickness=6, color=(0xDF / 0xFF, 0x29 / 0xFF, 0x35 / 0xFF))\n",
    "            self.camera_feed.draw_world_arrow(p, p_h, thickness=6, color=(0xFF / 0xFF, 0x87 / 0xFF, 0x1F / 0xFF))\n",
    "            self.camera_feed.update_window()\n",
    "\n",
    "        if self.record_data:                \n",
    "            p = self.robot.get_pose(self.AXES)\n",
    "            v = self.robot.get_velocity(self.AXES)\n",
    "            p_ref, v_ref = self.get_target(p)\n",
    "            F_ref = F_ref_curve[0]\n",
    "            F_h = self.robot.get_force(self.AXES)\n",
    "            self.data.append((t, dt, p[0], p[1], p[2], v[0], v[1], v[2], p_ref[0], p_ref[1], p_ref[2], v_ref[0], v_ref[1], v_ref[2], self.forward_state, F_h[0], F_h[1], F_h[2], self.P, self.V, c_p, c_v, F_ref[0], F_ref[1], F_ref[2], F_r[0], F_r[1], F_r[2], F_v[0], F_v[1], F_v[2], phrase, self.speaking_start_t, self.speaking_start_V, spoke_encouraging, spoke_instructional))\n",
    "\n",
    "    def shutdown(self) -> None:\n",
    "        self.robot.set_velocity(Robot.zeroed_translation_rotation())\n",
    "        if self.use_plotter:\n",
    "            self.plotter.close()\n",
    "\n",
    "        if self.record_data:\n",
    "            column_names = [\"t\", \"dt\", \"p_x\", \"p_y\", \"p_z\", \"v_x\", \"v_y\", \"v_z\", \"p_ref_x\", \"p_ref_y\", \"p_ref_z\", \"v_ref_x\", \"v_ref_y\", \"v_ref_z\", \"path_direction\", \"F_h_x\", \"F_h_y\", \"F_h_z\", \"P_hat\", \"V_hat\", \"c_p\", \"c_v\", \"F_ref_x\", \"F_ref_y\", \"F_ref_z\", \"F_r_x\", \"F_r_y\", \"F_r_z\", \"F_v_x\", \"F_v_y\", \"F_v_z\", \"phrase\", \"speaking_start_t\", \"speaking_start_V\", \"encouraging\", \"instructional\"]\n",
    "            pd.DataFrame(self.data, columns=column_names).to_csv(f'{time.time()}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = RobotApp(use_plotter=True, use_camera=False, record_data=False)\n",
    "app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guidance-controller",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
